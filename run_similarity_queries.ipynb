{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Similarity Queries\n",
    "==================\n",
    "\n",
    "Demonstrates querying a corpus for similar documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Corpus\n",
    "-------------------\n",
    "\n",
    "First, we need to create a corpus to work with.\n",
    "This step is the same as in the previous tutorial;\n",
    "if you completed it, feel free to skip to the next section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-22 12:57:42,789 : WARNING : unable to import 'smart_open.gcs', disabling that module\n",
      "2020-04-22 12:57:44,169 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-22 12:57:44,169 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]\n",
    "\n",
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]\n",
    "\n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity interface\n",
    "--------------------\n",
    "* We previously covered how create a VSM corpus & how to transform it between different vector spaces. \n",
    "* Next: determine **similarity between pairs of documents**, or **similarity between a specific document and a set of\n",
    "other documents** (such as a user query vs. indexed documents).\n",
    "* Basis: [Deerwester: Indexing by Latent Semantic Analysis](http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf) (1990).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-22 13:00:21,887 : INFO : using serial LSI version on this node\n",
      "2020-04-22 13:00:21,889 : INFO : updating model with new documents\n",
      "2020-04-22 13:00:21,890 : INFO : preparing a new chunk of documents\n",
      "2020-04-22 13:00:21,892 : INFO : using 100 extra samples and 2 power iterations\n",
      "2020-04-22 13:00:21,893 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2020-04-22 13:00:21,894 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2020-04-22 13:00:21,895 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2020-04-22 13:00:21,896 : INFO : computing the final decomposition\n",
      "2020-04-22 13:00:21,897 : INFO : keeping 2 factors (discarding 43.156% of energy spectrum)\n",
      "2020-04-22 13:00:21,898 : INFO : processed documents up to #9\n",
      "2020-04-22 13:00:21,899 : INFO : topic #0(3.341): 0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"response\" + 0.265*\"time\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"\n",
      "2020-04-22 13:00:21,900 : INFO : topic #1(2.542): 0.623*\"graph\" + 0.490*\"trees\" + 0.451*\"minors\" + 0.274*\"survey\" + -0.167*\"system\" + -0.141*\"eps\" + -0.113*\"human\" + 0.107*\"response\" + 0.107*\"time\" + -0.072*\"interface\"\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LSI enables identifying patterns and relationships between terms & topics. This LSI space is 2D (`num_topics = 2`) so there are two topics, but this is arbitrary. [more](https://en.wikipedia.org/wiki/Latent_semantic_indexing).\n",
    "\n",
    "* Assume a user typed in the query `\"Human computer interaction\"`. We want to sort our nine corpus documents in decreasing order of relevance to this query. \n",
    "\n",
    "* Unlike modern search engines, here we only concentrate on a single aspect of possible similarities---on apparent semantic relatedness of their texts (words). No hyperlinks, no random-walk static ranks, just a semantic extension over the boolean keyword match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.46182100453271735), (1, -0.07002766527899984)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]  # convert the query to LSI space\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We'll use [cosine similarity](http://en.wikipedia.org/wiki/Cosine_similarity) to find the two vectors' similarity. \n",
    "* Cosine similarity is a standard measure in Vector Space Modeling. When the vectors represent probability distributions,\n",
    "[other measures](http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Symmetrised_divergence) may be more appropriate.\n",
    "\n",
    "### Initializing query structures\n",
    "\n",
    "To prepare for similarity queries, we need to enter all documents which we want\n",
    "to compare against subsequent queries. In our case, they are the same nine documents\n",
    "used for training LSI, converted to 2-D LSA space. But that's only incidental, we\n",
    "might also be indexing a different corpus altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-22 13:10:50,200 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2020-04-22 13:10:50,202 : INFO : creating matrix with 9 documents and 2 features\n"
     ]
    }
   ],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])  # transform corpus to LSI space and index it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><h4>Warning</h4><p>The class :class:`similarities.MatrixSimilarity` is only appropriate when the whole\n",
    "  set of vectors fits into memory. For example, a corpus of one million documents\n",
    "  would require 2GB of RAM in a 256-dimensional LSI space, when used with this class.\n",
    "\n",
    "  Without 2GB of free RAM, you would need to use the :class:`similarities.Similarity` class.\n",
    "  This class operates in fixed memory, by splitting the index across multiple files on disk, called shards.\n",
    "  It uses :class:`similarities.MatrixSimilarity` and :class:`similarities.SparseMatrixSimilarity` internally,\n",
    "  so it is still fast, although slightly more complex.</p></div>\n",
    "\n",
    "* Index persistence is handled with :func:`save` and :func:`load` functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-22 13:11:59,713 : INFO : saving MatrixSimilarity object under /tmp/deerwester.index, separately None\n",
      "2020-04-22 13:11:59,718 : INFO : saved /tmp/deerwester.index\n",
      "2020-04-22 13:11:59,719 : INFO : loading MatrixSimilarity object from /tmp/deerwester.index\n",
      "2020-04-22 13:11:59,721 : INFO : loaded /tmp/deerwester.index\n"
     ]
    }
   ],
   "source": [
    "index.save('/tmp/deerwester.index')\n",
    "index = similarities.MatrixSimilarity.load('/tmp/deerwester.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/corpus.lda-c.index  /tmp/corpus.svmlight.index  /tmp/mymodel.index\n",
      "/tmp/corpus.low.index\t /tmp/deerwester.index\n",
      "/tmp/corpus.mm.index\t /tmp/deerwester.mm.index\n"
     ]
    }
   ],
   "source": [
    "!ls /tmp/*.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is true for all similarity indexing classes (:class:`similarities.Similarity`,\n",
    ":class:`similarities.MatrixSimilarity` and :class:`similarities.SparseMatrixSimilarity`).\n",
    "Also in the following, `index` can be an object of any of these. When in doubt,\n",
    "use :class:`similarities.Similarity`, as it is the most scalable version, and it also\n",
    "supports adding more documents to the index later.\n",
    "\n",
    "### Performing queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.998093), (1, 0.93748635), (2, 0.9984453), (3, 0.9865886), (4, 0.90755945), (5, -0.12416792), (6, -0.10639259), (7, -0.09879464), (8, 0.050041765)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi]  # perform a similarity query against the corpus\n",
    "print(list(enumerate(sims)))  # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cosine measure returns similarities in the range `<-1, 1>` (greater value = more similarity).\n",
    "* Sort in descending order, and obtain the final answer to the query `\"Human computer interaction\"`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0.9984453) Human machine interface for lab abc computer applications\n",
      "(0, 0.998093) A survey of user opinion of computer system response time\n",
      "(3, 0.9865886) The EPS user interface management system\n",
      "(1, 0.93748635) System and human system engineering testing of EPS\n",
      "(4, 0.90755945) Relation of user perceived response time to error measurement\n",
      "(8, 0.050041765) The generation of random binary unordered trees\n",
      "(7, -0.09879464) The intersection graph of paths in trees\n",
      "(6, -0.10639259) Graph minors IV Widths of trees and well quasi ordering\n",
      "(5, -0.12416792) Graph minors A survey\n"
     ]
    }
   ],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "for i, s in enumerate(sims):\n",
    "    print(s, documents[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: documents no. 2 (``\"The EPS user interface management system\"``) and 4 (``\"Relation of user perceived response time to error measurement\"``) would never be returned by a standard boolean fulltext search, because they do not share any common words with ``\"Human\n",
    "computer interaction\"``. However, after applying LSI, we see both of them received quite high similarity scores (no. 2 is actually the most similar!), which corresponds to our intuition of them sharing a \"computer-human\" related topic with the query. In fact, this semantic\n",
    "generalization is the reason why we apply transformations and do topic modelling in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#img = mpimg.imread('run_similarity_queries.png')\n",
    "#imgplot = plt.imshow(img)\n",
    "#plt.axis('off')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
