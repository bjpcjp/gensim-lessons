{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Doc2Vec Model\n",
    "=============\n",
    "\n",
    "Introduces Gensim's Doc2Vec model and demonstrates its use on the Lee Corpus.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec models (represents) each document as a _core_concepts_vector_.\n",
    "\n",
    "Bag-of-words Weaknesses\n",
    "--------------------\n",
    "\n",
    "* Bag-of-words models are surprisingly effective, but have several weaknesses.\n",
    "* First, they forget about word order: \"John likes Mary\" and \"Mary likes John\" correspond to identical vectors. \n",
    "    - There is a solution: [bag of n-grams](https://en.wikipedia.org/wiki/N-gram) models consider word phrases of length n to represent documents as fixed-length vectors to capture local word order but suffer from data sparsity and high dimensionality.\n",
    "* Second, the model does not try to learn the meaning of the underlying words - therefore the distance between vectors doesn't always reflect the difference in meaning.\n",
    "    - _Word2Vec_ addresses this problem.\n",
    "\n",
    "Word2Vec\n",
    "--------\n",
    "* *Word2Vec* embeds words in a lower-dimensional vector space using a shallow neural network. It returns a set of word-vectors where vectors close together in vector space have similar **contextual** meanings, ie 'strong' & 'powerful' would be close together; 'strong' & 'Paris' would not.\n",
    "\n",
    "* *Word2Vec* allows us to build vectors for each **word** in a document. But what if we want to build a vector for the **entire document**? We could average the word vectors for each word, but there is a better way.\n",
    "\n",
    "Introducing: Paragraph Vector\n",
    "-----------------------------\n",
    "* IMPORTANT: In Gensim, we refer to the Paragraph Vector model as 'Doc2Vec'.\n",
    "\n",
    "* Le and Mikolov in 2014 introduced the [Doc2Vec algorithm](https://cs.stanford.edu/~quocle/paragraph_vector.pdf), which usually outperforms simple averaging of *Word2Vec* vectors.\n",
    "\n",
    "* The idea is to act as if a document has another floating word-like vector, which contributes to all training predictions, and is updated like other word-vectors, but we will call it a doc-vector.\n",
    "\n",
    "* There are two implementations:\n",
    "    1. Paragraph Vector - Distributed Memory (PV-DM)\n",
    "    2. Paragraph Vector - Distributed Bag of Words (PV-DBOW)\n",
    "\n",
    "* PV-DM is analogous to Word2Vec CBOW. The doc-vectors are obtained by training a neural network on the synthetic task of predicting a center word based an average of both context word-vectors and the full document's doc-vector.\n",
    "\n",
    "* PV-DBOW is analogous to Word2Vec SG. The doc-vectors are obtained by training a neural network on the synthetic task of predicting a target word just from the full document's doc-vector. (It is also common to combine this with skip-gram testing, using both the doc-vector and nearby word-vectors to predict a single target word, but only one at a time.)\n",
    "\n",
    "Prepare the [Lee Background Corpus](https://hekyll.services.adelaide.edu.au/dspace/bitstream/2440/28910/1/hdl_28910.pdf)\n",
    "----------------------------------\n",
    "\n",
    "* The corpus is included in gensim. It contains 314 documents selected from the Australian Broadcasting Corporationâ€™s news mail service, which provides text e-mails of headline stories and covers a number of broad topics.\n",
    "\n",
    "* We'll test our model using the much shorter [Lee Corpus](https://hekyll.services.adelaide.edu.au/dspace/bitstream/2440/28910/1/hdl_28910.pdf), which contains 50 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os, gensim\n",
    "\n",
    "test_data_dir  = os.path.join(gensim.__path__[0], 'test', 'test_data')\n",
    "lee_train_file = os.path.join(test_data_dir, 'lee_background.cor')\n",
    "lee_test_file  = os.path.join(test_data_dir, 'lee.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/d2v-lee-v0.13.0\n",
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/lee_background.cor\n",
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/lee.cor\n",
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/lee_fasttext\n",
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/lee_fasttext.bin\n",
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/lee_fasttext_new.bin\n",
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/lee_fasttext.vec\n",
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/pang_lee_polarity.cor\n",
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/pang_lee_polarity_fasttext.bin\n",
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/pang_lee_polarity_fasttext.vec\n",
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/varembed_lee_subcorpus.cor\n",
      "/home/bjpcjp/.local/lib/python3.6/site-packages/gensim/test/test_data/w2v-lee-v0.12.0\n"
     ]
    }
   ],
   "source": [
    "!ls $test_data_dir/*lee*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Function to Read and Preprocess Text\n",
    "---------------------------------------------\n",
    "\n",
    "* Below, we define a function to:\n",
    "    - open the train/test file (with latin encoding)\n",
    "    - read the file line-by-line\n",
    "    - pre-process each line (tokenize text into words, remove punctuation, set to lowercase, etc)\n",
    "\n",
    "The file we're reading is a **corpus**. Each line of the file is a **document**.\n",
    "\n",
    "* To train the model, we'll need to associate a tag/number with each document of the training corpus. In our case, the tag is simply the zero-based line number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import smart_open\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "train_corpus = list(read_corpus(lee_train_file))\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the training corpus\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['hundreds', 'of', 'people', 'have', 'been', 'forced', 'to', 'vacate', 'their', 'homes', 'in', 'the', 'southern', 'highlands', 'of', 'new', 'south', 'wales', 'as', 'strong', 'winds', 'today', 'pushed', 'huge', 'bushfire', 'towards', 'the', 'town', 'of', 'hill', 'top', 'new', 'blaze', 'near', 'goulburn', 'south', 'west', 'of', 'sydney', 'has', 'forced', 'the', 'closure', 'of', 'the', 'hume', 'highway', 'at', 'about', 'pm', 'aedt', 'marked', 'deterioration', 'in', 'the', 'weather', 'as', 'storm', 'cell', 'moved', 'east', 'across', 'the', 'blue', 'mountains', 'forced', 'authorities', 'to', 'make', 'decision', 'to', 'evacuate', 'people', 'from', 'homes', 'in', 'outlying', 'streets', 'at', 'hill', 'top', 'in', 'the', 'new', 'south', 'wales', 'southern', 'highlands', 'an', 'estimated', 'residents', 'have', 'left', 'their', 'homes', 'for', 'nearby', 'mittagong', 'the', 'new', 'south', 'wales', 'rural', 'fire', 'service', 'says', 'the', 'weather', 'conditions', 'which', 'caused', 'the', 'fire', 'to', 'burn', 'in', 'finger', 'formation', 'have', 'now', 'eased', 'and', 'about', 'fire', 'units', 'in', 'and', 'around', 'hill', 'top', 'are', 'optimistic', 'of', 'defending', 'all', 'properties', 'as', 'more', 'than', 'blazes', 'burn', 'on', 'new', 'year', 'eve', 'in', 'new', 'south', 'wales', 'fire', 'crews', 'have', 'been', 'called', 'to', 'new', 'fire', 'at', 'gunning', 'south', 'of', 'goulburn', 'while', 'few', 'details', 'are', 'available', 'at', 'this', 'stage', 'fire', 'authorities', 'says', 'it', 'has', 'closed', 'the', 'hume', 'highway', 'in', 'both', 'directions', 'meanwhile', 'new', 'fire', 'in', 'sydney', 'west', 'is', 'no', 'longer', 'threatening', 'properties', 'in', 'the', 'cranebrook', 'area', 'rain', 'has', 'fallen', 'in', 'some', 'parts', 'of', 'the', 'illawarra', 'sydney', 'the', 'hunter', 'valley', 'and', 'the', 'north', 'coast', 'but', 'the', 'bureau', 'of', 'meteorology', 'claire', 'richards', 'says', 'the', 'rain', 'has', 'done', 'little', 'to', 'ease', 'any', 'of', 'the', 'hundred', 'fires', 'still', 'burning', 'across', 'the', 'state', 'the', 'falls', 'have', 'been', 'quite', 'isolated', 'in', 'those', 'areas', 'and', 'generally', 'the', 'falls', 'have', 'been', 'less', 'than', 'about', 'five', 'millimetres', 'she', 'said', 'in', 'some', 'places', 'really', 'not', 'significant', 'at', 'all', 'less', 'than', 'millimetre', 'so', 'there', 'hasn', 'been', 'much', 'relief', 'as', 'far', 'as', 'rain', 'is', 'concerned', 'in', 'fact', 'they', 've', 'probably', 'hampered', 'the', 'efforts', 'of', 'the', 'firefighters', 'more', 'because', 'of', 'the', 'wind', 'gusts', 'that', 'are', 'associated', 'with', 'those', 'thunderstorms'], tags=[0]),\n",
      " TaggedDocument(words=['indian', 'security', 'forces', 'have', 'shot', 'dead', 'eight', 'suspected', 'militants', 'in', 'night', 'long', 'encounter', 'in', 'southern', 'kashmir', 'the', 'shootout', 'took', 'place', 'at', 'dora', 'village', 'some', 'kilometers', 'south', 'of', 'the', 'kashmiri', 'summer', 'capital', 'srinagar', 'the', 'deaths', 'came', 'as', 'pakistani', 'police', 'arrested', 'more', 'than', 'two', 'dozen', 'militants', 'from', 'extremist', 'groups', 'accused', 'of', 'staging', 'an', 'attack', 'on', 'india', 'parliament', 'india', 'has', 'accused', 'pakistan', 'based', 'lashkar', 'taiba', 'and', 'jaish', 'mohammad', 'of', 'carrying', 'out', 'the', 'attack', 'on', 'december', 'at', 'the', 'behest', 'of', 'pakistani', 'military', 'intelligence', 'military', 'tensions', 'have', 'soared', 'since', 'the', 'raid', 'with', 'both', 'sides', 'massing', 'troops', 'along', 'their', 'border', 'and', 'trading', 'tit', 'for', 'tat', 'diplomatic', 'sanctions', 'yesterday', 'pakistan', 'announced', 'it', 'had', 'arrested', 'lashkar', 'taiba', 'chief', 'hafiz', 'mohammed', 'saeed', 'police', 'in', 'karachi', 'say', 'it', 'is', 'likely', 'more', 'raids', 'will', 'be', 'launched', 'against', 'the', 'two', 'groups', 'as', 'well', 'as', 'other', 'militant', 'organisations', 'accused', 'of', 'targetting', 'india', 'military', 'tensions', 'between', 'india', 'and', 'pakistan', 'have', 'escalated', 'to', 'level', 'not', 'seen', 'since', 'their', 'war'], tags=[1])]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(train_corpus[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The training corpus (a list of lists; no tags):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'national', 'executive', 'of', 'the', 'strife', 'torn', 'democrats', 'last', 'night', 'appointed', 'little', 'known', 'west', 'australian', 'senator', 'brian', 'greig', 'as', 'interim', 'leader', 'shock', 'move', 'likely', 'to', 'provoke', 'further', 'conflict', 'between', 'the', 'party', 'senators', 'and', 'its', 'organisation', 'in', 'move', 'to', 'reassert', 'control', 'over', 'the', 'party', 'seven', 'senators', 'the', 'national', 'executive', 'last', 'night', 'rejected', 'aden', 'ridgeway', 'bid', 'to', 'become', 'interim', 'leader', 'in', 'favour', 'of', 'senator', 'greig', 'supporter', 'of', 'deposed', 'leader', 'natasha', 'stott', 'despoja', 'and', 'an', 'outspoken', 'gay', 'rights', 'activist'], ['cash', 'strapped', 'financial', 'services', 'group', 'amp', 'has', 'shelved', 'million', 'plan', 'to', 'buy', 'shares', 'back', 'from', 'investors', 'and', 'will', 'raise', 'million', 'in', 'fresh', 'capital', 'after', 'profits', 'crashed', 'in', 'the', 'six', 'months', 'to', 'june', 'chief', 'executive', 'paul', 'batchelor', 'said', 'the', 'result', 'was', 'solid', 'in', 'what', 'he', 'described', 'as', 'the', 'worst', 'conditions', 'for', 'stock', 'markets', 'in', 'years', 'amp', 'half', 'year', 'profit', 'sank', 'per', 'cent', 'to', 'million', 'or', 'share', 'as', 'australia', 'largest', 'investor', 'and', 'fund', 'manager', 'failed', 'to', 'hit', 'projected', 'per', 'cent', 'earnings', 'growth', 'targets', 'and', 'was', 'battered', 'by', 'falling', 'returns', 'on', 'share', 'markets']]\n"
     ]
    }
   ],
   "source": [
    "print(test_corpus[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model\n",
    "------------------\n",
    "* Create a Doc2Vec model with a 50-dimension vector\n",
    "* Iterate over the training corpus 40 times\n",
    "* Set minimum word count to 2 - to discard words with very few occurrences.\n",
    "* Typical iteration counts in [Paragraph Vector paper](https://cs.stanford.edu/~quocle/paragraph_vector.pdf) results, using 10s-of-thousands to millions of docs, are 10-20. More iterations take more time & result in diminishing returns.\n",
    "* This is a small dataset (300 documents) with shortish documents (a few hundred words). Adding training passes can help with such small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The vocabulary is a dictionary (_model.wv.vocab_) of all unique words extracted from the training corpus along with the count (_model.wv.vocab['penalty'].count_ for counts for the word 'penalty')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the BLAS library is being used, this should take no more than 3 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the trained model to infer a vector for any piece of text by passing a list of words to _model.infer_vector_. This vector can then be compared with other vectors via cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20484999  0.29121417 -0.09885011 -0.10435056 -0.07113887  0.25424787\n",
      " -0.23287696 -0.13940692  0.3316893   0.31415215  0.03712632 -0.0121164\n",
      "  0.13449863  0.15245944 -0.13940471 -0.05893684 -0.09646172 -0.06737366\n",
      " -0.10485979 -0.2108823   0.1520444   0.08312634 -0.05644798 -0.0951256\n",
      "  0.12901355  0.067581    0.04278953 -0.10728648  0.26051214  0.07028764\n",
      " -0.02052462 -0.13310336 -0.00821643 -0.00613631  0.28000695  0.06918957\n",
      "  0.00604747 -0.06568436  0.19088987  0.02761287 -0.00912968 -0.06838579\n",
      " -0.16202644 -0.13949049  0.02260514  0.06482696  0.02777114  0.08233481\n",
      "  0.2015555   0.03069362]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _infer_vector()_ does *not* take a string, but rather a list of string tokens, which should have already been tokenized the same way as the ``words`` property of original training document objects.\n",
    "* Repeated inferences of the same text can return slightly different vectors. This is because the underlying training/inference algorithms are an iterative approximation problem that makes use of internal randomization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing the Model\n",
    "-------------------\n",
    "* To assess our new model, we'll first new vectors for each document of the training corpus, compare the inferred vectors with the training corpus, and then returning the rank of the document based on self-similarity.\n",
    "* Basically, we're pretending as if the training corpus is some new unseen data and seeing how they compare with the trained model. The expectation is that we've probably overfit our model (i.e., all of the ranks will be less than 2) and so we should be able to find similar documents very easily.\n",
    "* Additionally, we'll keep track of the second ranks for a comparison of less similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ranks, second_ranks = [],[]\n",
    "\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims            = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank            = [docid for docid, sim in sims].index(doc_id)\n",
    "    \n",
    "    ranks.append(rank)\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 293, 1: 7})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* >95% of the inferred documents are found to be most similar to itself; ~5% of the time it is (mistakenly) most similar to another document. Checking the inferred-vector against a training-vector is a sort of 'sanity check' as to whether the model is behaving in a usefully consistent manner, though not a real 'accuracy' value. \n",
    "* We can take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (299): Â«australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as wellÂ»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (299, 0.9464671611785889): Â«australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as wellÂ»\n",
      "\n",
      "SECOND-MOST (104, 0.8286285996437073): Â«australian cricket captain steve waugh has supported fast bowler brett lee after criticism of his intimidatory bowling to the south african tailenders in the first test in adelaide earlier this month lee was fined for giving new zealand tailender shane bond an unsportsmanlike send off during the third test in perth waugh says tailenders should not be protected from short pitched bowling these days you re earning big money you ve got responsibility to learn how to bat he said mean there no times like years ago when it was not professional and sort of bowlers code these days you re professional our batsmen work very hard at their batting and expect other tailenders to do likewise meanwhile waugh says his side will need to guard against complacency after convincingly winning the first test by runs waugh says despite the dominance of his side in the first test south africa can never be taken lightly it only one test match out of three or six whichever way you want to look at it so there lot of work to go he said but it nice to win the first battle definitely it gives us lot of confidence going into melbourne you know the big crowd there we love playing in front of the boxing day crowd so that will be to our advantage as well south africa begins four day match against new south wales in sydney on thursday in the lead up to the boxing day test veteran fast bowler allan donald will play in the warm up match and is likely to take his place in the team for the second test south african captain shaun pollock expects much better performance from his side in the melbourne test we still believe that we didn play to our full potential so if we can improve on our aspects the output we put out on the field will be lot better and we still believe we have side that is good enough to beat australia on our day he saidÂ»\n",
      "\n",
      "MEDIAN (170, 0.28674831986427307): Â«the united states federal reserve has cut key interest rate by quarter point to year low of per cent and left the door open to further easing to help bring the us economy out of recession it was the th cut this year to the federal funds target rate and the fourth since the september suicide attacks in new york and washington the key rate which determines overnight borrowing costs between banks is at its lowest level since july policy makers also cut the discount rate at which commercial banks can borrow from the federal reserve by the same quarter point margin to per cent economic activity remains soft with underlying inflation likely to edge lower from relatively modest levels the federal open market committee said in written statement the us economy officially slid into recession in march ending an unprecedented year expansion period the terrorist shockwave has escalated the task of rebuilding growth experts saidÂ»\n",
      "\n",
      "LEAST (1, -0.12061045318841934): Â«indian security forces have shot dead eight suspected militants in night long encounter in southern kashmir the shootout took place at dora village some kilometers south of the kashmiri summer capital srinagar the deaths came as pakistani police arrested more than two dozen militants from extremist groups accused of staging an attack on india parliament india has accused pakistan based lashkar taiba and jaish mohammad of carrying out the attack on december at the behest of pakistani military intelligence military tensions have soared since the raid with both sides massing troops along their border and trading tit for tat diplomatic sanctions yesterday pakistan announced it had arrested lashkar taiba chief hafiz mohammed saeed police in karachi say it is likely more raids will be launched against the two groups as well as other militant organisations accused of targetting india military tensions between india and pakistan have escalated to level not seen since their warÂ»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): Â«{}Â»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: Â«%sÂ»\\n' % (label, \n",
    "                              sims[index], \n",
    "                              ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: the most similar document (usually the same text) has a similarity score approaching 1.0. The similarity score for the second-ranked documents should be significantly lower (assuming the documents are in fact different) and the reasoning becomes obvious when we examine the text itself.\n",
    "\n",
    "* We can run the next cell repeatedly to see a sampling other target-document comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (26): Â«pakistan president pervez musharraf says he is ready to meet indian prime minister atal behari vajpayee as fears grow of war between the two countries tensions have escalated since suicide attack on the indian parliament two weeks ago india alleges the attack was backed by the pakistani intelligence service general musharraf says pakistan will never initiate conflict between the two countries he says he is prepared to hold talks with the indian prime minister at regional summit in nepal next week don mind meeting him but as ve said once before you can clap with one hand general musharraf said if there is willingness from the other side there will be willingness from my sideÂ»\n",
      "\n",
      "Similar Document (12, 0.7191126942634583): Â«president general pervez musharraf says pakistan wants to defuse the brewing crisis with india but was prepared to respond vigorously to any attack pakistan stands for peace pakistan wants peace pakistan wants to reduce tension he said let the two countries move towards peace and harmony however pakistan has taken all counter measures if any war is thrust on pakistan the pakistan armed forces and the million people of pakistan are fully prepared to face all consequences with all their might the president said he had received the support of all political parties president musharraf also said he welcomed the intervention of the international community in trying to defuse the potentially explosive crisis we would like anybody to play useful and positive role in defusing the tension the united states the european union and the group of eight industrialised nations among others have all called on india and pakistan to exercise restraint and resolve the stand off through dialogue president musharraf repeated his offer of holding talks with indian prime minister atal behari vajpayee am for dialogue and keep on saying this and india keeps on rejecting which gives me feeling that am begging to india if they accept it we do not reject it at all he said on friday he said he was willing to meet prime minister vajpayee on the sidelines of the january south asian association for regional cooperation saarc summit in nepal india ruled out any face to face talks military tensions erupted between india and pakistan after the bloody december raid on the indian parliament india accuses pakistan military intelligence of masterminding the assault but pakistan denies the allegation with both countries massing troops along the border pakistan foreign minister abdul sattar warned saturday that the dispute was growing dangerously tense and any small act of provocation could snowball into conflict president musharraf said one of the goals of sunday meeting was to take stock of the internal situation the domestic environment want to eradicate militancy extremism intolerance from pakistani society and also said would like to eradicate any form of terrorism from the soil of pakistan however he warned the tension that has mounted on our eastern border in fact is creating obstacles and hurdlesÂ»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "import random\n",
    "\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "sim_id = second_ranks[doc_id]\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): Â«{}Â»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print('Similar Document {}: Â«{}Â»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Model\n",
    "-----------------\n",
    "\n",
    "Using the same approach above, we'll infer the vector for a randomly chosen\n",
    "test document, and compare the document to our model by eye.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (6): Â«senior members of the saudi royal family paid at least million to osama bin laden terror group and the taliban for an agreement his forces would not attack targets in saudi arabia according to court documents the papers filed in us billion billion lawsuit in the us allege the deal was made after two secret meetings between saudi royals and leaders of al qa ida including bin laden the money enabled al qa ida to fund training camps in afghanistan later attended by the september hijackers the disclosures will increase tensions between the us and saudi arabiaÂ»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (261, 0.5970593690872192): Â«afghan opposition leaders meeting in germany have reached an agreement after seven days of talks on the structure of an interim post taliban government for afghanistan the agreement calls for the immediate assembly of temporary group of multi national peacekeepers in kabul and possibly other areas the four afghan factions have approved plan for member ruling council composed of chairman five deputy chairmen and other members the council would govern afghanistan for six months at which time traditional afghan assembly called loya jirga would be convened to decide on more permanent structure the agreement calls for elections within two yearsÂ»\n",
      "\n",
      "MEDIAN (277, 0.14572396874427795): Â«israeli soldiers have shot dead five palestinians in two west bank towns an israeli military source said the soldiers shot four palestinians near jenin when palestinian gunmen opened fire on an army patrol and the troops returned fire another palestinian was killed by israeli soldiers near the west bank city of tulkarem palestinian security source said meanwhile palestinian police have arrested three senior leaders of the hardline hamas group in crackdown that netted more than islamic militants following wave of suicide attacks in israel palestinian security source told the afp news agency hamas official confirmed the arrests of two senior leaders ismail abu shanab and ismail haniya and said police have issued arrest warrants for another two but he refused to name them the security source said more than militants from hamas and the smaller islamic jihad were rounded after yasser arafat palestinian leadership vowed to crackdown on them for wave of anti israeli suicide assaults most of the arrests came after the palestinian leadership declared state of emergency in the palestinian territories giving police sweeping powers to round up militantsÂ»\n",
      "\n",
      "LEAST (264, -0.34821683168411255): Â«widespread damage from yesterday violent storms in new south wales has forced the government to declare more areas of the state natural disaster zones up to volunteers and fire fighters are continuing the big mop up state emergency services ses volunteers are still clearing some of thehuge trees that came crashing down on homes in sydney north martin walker was sitting on his back deck when the storm struck it sounded like freight train was about to hit our house you could hear it coming with such ferocity and as it hit all the trees just seemed to bend and there was stuff hitting the back of our house mr walker said pitwater bankstown sutherland hurstville and liverpool in sydney and gunnedah and tamworth in the state north west have been added to the list of natural disaster areas new south wales premier bob carr has inspected one of the worst hit parts wahroonga in sydney north struck by the of this storm damage we ve had storms before but never winds of this force and it was uneven and unpredictable in its impact mr carr said the final damage bill is expected to be more than millionÂ»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id          = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims            = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "print('Test Document ({}): Â«{}Â»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: Â«%sÂ»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources\n",
    "----------\n",
    "\n",
    "* [Word2Vec Paper](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "* [Doc2Vec Paper](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)\n",
    "* [Dr. Michael D. Lee's Website](http://faculty.sites.uci.edu/mdlee)\n",
    "* [Lee Corpus](http://faculty.sites.uci.edu/mdlee/similarity-data)__\n",
    "* [IMDB Doc2Vec Tutorial](doc2vec-IMDB.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
